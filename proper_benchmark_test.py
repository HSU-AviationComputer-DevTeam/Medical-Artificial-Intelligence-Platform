#!/usr/bin/env python3
"""
ì˜¬ë°”ë¥¸ E5 vs Gemini ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
ê° ëª¨ë¸ì€ ìì‹ ì˜ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©
"""

import json
import logging
import os
import sys
import time
import warnings
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    import faiss
    from google import genai
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import FAISS
    print("âœ… í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("pip install faiss-cpu langchain langchain-community google-generativeai ì‹¤í–‰ í•„ìš”")
    sys.exit(1)

class GeminiEmbeddings:
    """Gemini ì„ë² ë”© í´ë˜ìŠ¤ (ì²¨ë¶€ëœ ì½”ë“œ ì°¸ê³ )"""
    
    def __init__(self, api_key):
        self.client = genai.Client(api_key=api_key)
        self.last_api_call_time = 0
        self.api_call_interval = 15  # 15ì´ˆ ê°„ê²©
    
    def _wait_for_rate_limit(self):
        """API ìš”ì²­ ì „ ëŒ€ê¸° ì‹œê°„ ê´€ë¦¬"""
        current_time = time.time()
        time_since_last_call = current_time - self.last_api_call_time
        
        if time_since_last_call < self.api_call_interval:
            wait_time = self.api_call_interval - time_since_last_call
            print(f"â³ API ì œí•œìœ¼ë¡œ {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(wait_time)
        
        self.last_api_call_time = time.time()
    
    def embed_documents(self, texts):
        """ë¬¸ì„œ ì„ë² ë”© - 3072ì°¨ì› ë²¡í„° ìƒì„±"""
        if isinstance(texts, str):
            texts = [texts]
        
        self._wait_for_rate_limit()
        
        result = self.client.models.embed_content(
            model="models/gemini-embedding-exp-03-07",  # 3072ì°¨ì› ëª¨ë¸
            contents=texts,
            config={"task_type": "retrieval_document"}
        )
        return [embedding.values for embedding in result.embeddings]
    
    def embed_query(self, text):
        """ì¿¼ë¦¬ ì„ë² ë”© - 3072ì°¨ì› ë²¡í„° ìƒì„±"""
        self._wait_for_rate_limit()
        
        result = self.client.models.embed_content(
            model="models/gemini-embedding-exp-03-07",  # 3072ì°¨ì› ëª¨ë¸
            contents=[text],
            config={"task_type": "retrieval_query"}
        )
        return result.embeddings[0].values
    
    def __call__(self, text):
        """ì§ì ‘ í˜¸ì¶œ ì‹œ ì¿¼ë¦¬ ì„ë² ë”© ì‹¤í–‰"""
        return self.embed_query(text)

class ProperVectorStoreBenchmark:
    """ì˜¬ë°”ë¥¸ ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬"""
    
    def __init__(self, gemini_api_key=None):
        self.results = {}
        self.gemini_api_key = gemini_api_key
        
    def load_e5_vector_store(self, store_path: str):
        """E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ (E5 ëª¨ë¸ ì‚¬ìš©)"""
        try:
            print(f"ğŸ”„ E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©: {store_path}")
            
            # E5 ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embedding_model = HuggingFaceEmbeddings(
                model_name="intfloat/multilingual-e5-large",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            
            # E5ìš© FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            vector_store = FAISS.load_local(
                store_path,
                embedding_model,
                allow_dangerous_deserialization=True
            )
            
            print(f"âœ… E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
            print(f"   - ë²¡í„° ê°œìˆ˜: {vector_store.index.ntotal}")
            print(f"   - ë²¡í„° ì°¨ì›: {vector_store.index.d}")
            
            return vector_store, embedding_model
            
        except Exception as e:
            print(f"âŒ E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None
    
    def load_gemini_vector_store(self, store_path: str):
        """Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ (Gemini ëª¨ë¸ ì‚¬ìš©)"""
        try:
            print(f"ğŸ”„ Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©: {store_path}")
            
            if not self.gemini_api_key:
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°
                self.gemini_api_key = os.getenv('GOOGLE_API_KEY')
                if not self.gemini_api_key:
                    print("âš ï¸ GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return None, None
            
            # Gemini ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ì²¨ë¶€ëœ ì½”ë“œ ë°©ì‹ ì‚¬ìš©)
            embedding_model = GeminiEmbeddings(self.gemini_api_key)
            
            # Geminiìš© FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            vector_store = FAISS.load_local(
                store_path,
                embedding_model,
                allow_dangerous_deserialization=True
            )
            
            print(f"âœ… Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
            print(f"   - ë²¡í„° ê°œìˆ˜: {vector_store.index.ntotal}")
            print(f"   - ë²¡í„° ì°¨ì›: {vector_store.index.d}")
            
            return vector_store, embedding_model
            
        except Exception as e:
            print(f"âŒ Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None

    def precision_at_k(self, relevant_docs: List[str], retrieved_docs: List[Dict], k: int) -> float:
        """Precision@K ê³„ì‚° (ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ìš©)"""
        if k == 0 or not retrieved_docs:
            return 0.0
        
        retrieved_k = retrieved_docs[:k]
        relevant_retrieved = 0
        
        for doc in retrieved_k:
            # ë¬¸ì„œ ë‚´ìš©ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
            content = doc.page_content.lower()
            for relevant_concept in relevant_docs:
                if relevant_concept.lower() in content:
                    relevant_retrieved += 1
                    break
        
        return relevant_retrieved / k

    def perform_search_benchmark(self, vector_store, model_name: str, test_queries: List[Dict]):
        """ì‹¤ì œ ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nğŸ” {model_name} ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        search_times = []
        precision_scores = []
        search_results = []
        
        for i, query_data in enumerate(test_queries):
            query = query_data["query"]
            expected_concepts = query_data["relevant_concepts"]
            
            print(f"   {i+1}. ì¿¼ë¦¬: '{query}'")
            
            # ê²€ìƒ‰ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            try:
                # ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
                results = vector_store.similarity_search(query, k=5)
                search_time = time.time() - start_time
                search_times.append(search_time)
                
                # Precision@5 ê³„ì‚°
                precision = self.precision_at_k(expected_concepts, results, 5)
                precision_scores.append(precision)
                
                print(f"      ê²€ìƒ‰ ì‹œê°„: {search_time*1000:.1f}ms")
                print(f"      Precision@5: {precision:.3f}")
                
                # ìƒìœ„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                if results:
                    preview = results[0].page_content[:100].replace('\n', ' ')
                    print(f"      ìƒìœ„ ê²°ê³¼: {preview}...")
                
                search_results.append({
                    "query": query,
                    "search_time": search_time,
                    "precision": precision,
                    "num_results": len(results)
                })
                
            except Exception as e:
                print(f"      âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                search_times.append(float('inf'))
                precision_scores.append(0.0)
        
        # ì„±ëŠ¥ ìš”ì•½
        valid_times = [t for t in search_times if t != float('inf')]
        avg_search_time = np.mean(valid_times) if valid_times else float('inf')
        avg_precision = np.mean(precision_scores)
        
        print(f"\nğŸ“Š {model_name} ì„±ëŠ¥ ìš”ì•½:")
        if avg_search_time != float('inf'):
            print(f"   í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time*1000:.1f}ms")
            print(f"   í‰ê·  Precision@5: {avg_precision:.3f}")
            print(f"   ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {1/avg_search_time:.1f} QPS")
        else:
            print(f"   âŒ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨")
        
        return {
            "model_name": model_name,
            "avg_search_time": avg_search_time,
            "avg_precision": avg_precision,
            "qps": 1/avg_search_time if avg_search_time != float('inf') else 0,
            "search_results": search_results
        }

def create_medical_test_queries():
    """ì˜ë£Œ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìƒì„±"""
    return [
        {
            "query": "ë‹¹ë‡¨ë³‘ í™˜ì í˜ˆë‹¹ ê´€ë¦¬",
            "relevant_concepts": ["ë‹¹ë‡¨ë³‘", "í˜ˆë‹¹", "ì¸ìŠë¦°", "í˜ˆë‹¹ì¡°ì ˆ"]
        },
        {
            "query": "ê³ í˜ˆì•• ì§„ë‹¨ ì¹˜ë£Œ",
            "relevant_concepts": ["ê³ í˜ˆì••", "í˜ˆì••", "í˜ˆì••ì¸¡ì •", "í˜ˆì••ì•½"]
        },
        {
            "query": "ì‹¬ì¥ë³‘ ì¦ìƒ",
            "relevant_concepts": ["ì‹¬ì¥", "ì‹¬ê·¼ê²½ìƒ‰", "í˜‘ì‹¬ì¦", "í‰í†µ"]
        },
        {
            "query": "íë ´ ì§„ë‹¨",
            "relevant_concepts": ["íë ´", "ê¸°ì¹¨", "ë°œì—´", "í˜¸í¡"]
        },
        {
            "query": "ë‡Œì¡¸ì¤‘ ì‘ê¸‰ì²˜ì¹˜",
            "relevant_concepts": ["ë‡Œì¡¸ì¤‘", "ë§ˆë¹„", "ì‘ê¸‰", "ë‡Œ"]
        },
        {
            "query": "ê°„ì—¼ ê²€ì‚¬",
            "relevant_concepts": ["ê°„ì—¼", "ê°„", "ê°„ê¸°ëŠ¥", "ê²€ì‚¬"]
        }
    ]

def run_proper_benchmark():
    """ì˜¬ë°”ë¥¸ ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    
    print("ğŸš€ ì˜¬ë°”ë¥¸ E5 vs Gemini ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("=" * 60)
    print("ğŸ’¡ ê° ëª¨ë¸ì€ ìì‹ ì˜ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
    print("   - E5 ëª¨ë¸ â†’ medical_vector_store_e5")
    print("   - Gemini ëª¨ë¸ â†’ medical_vector_store")
    print("=" * 60)
    
    # Gemini API í‚¤ í™•ì¸
    gemini_api_key = os.getenv('GOOGLE_API_KEY')
    if not gemini_api_key:
        print("âš ï¸ GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        gemini_api_key = input("ğŸ”‘ Google API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not gemini_api_key:
            print("âŒ Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return {}
    
    # ë²¤ì¹˜ë§ˆí¬ ê°ì²´ ìƒì„±
    benchmark = ProperVectorStoreBenchmark(gemini_api_key)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„
    test_queries = create_medical_test_queries()
    print(f"ğŸ“‹ ì¤€ë¹„ëœ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
    
    # ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ ì„¤ì • (ì˜¬ë°”ë¥¸ ë§¤ì¹­)
    base_path = "VectorStore2/vector_stores"
    e5_path = f"{base_path}/medical_vector_store_e5"        # E5 ì „ìš©
    gemini_path = f"{base_path}/medical_vector_store"       # Gemini ì „ìš©
    
    results = {}
    
    # 1. E5 ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ (E5 ëª¨ë¸ ì‚¬ìš©)
    if os.path.exists(e5_path):
        print(f"\nğŸ” E5 ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ (E5 ëª¨ë¸ ì‚¬ìš©)")
        e5_store, e5_model = benchmark.load_e5_vector_store(e5_path)
        
        if e5_store:
            e5_results = benchmark.perform_search_benchmark(
                e5_store, "E5-Large", test_queries
            )
            results["E5"] = e5_results
        else:
            print("âŒ E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨")
    else:
        print(f"âš ï¸ E5 ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ ì—†ìŒ: {e5_path}")
    
    # 2. Gemini ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ (Gemini ëª¨ë¸ ì‚¬ìš©)
    if os.path.exists(gemini_path):
        print(f"\nğŸ” Gemini ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ (Gemini ëª¨ë¸ ì‚¬ìš©)")
        gemini_store, gemini_model = benchmark.load_gemini_vector_store(gemini_path)
        
        if gemini_store:
            gemini_results = benchmark.perform_search_benchmark(
                gemini_store, "Gemini-exp-03-07", test_queries
            )
            results["Gemini"] = gemini_results
        else:
            print("âŒ Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨")
    else:
        print(f"âš ï¸ Gemini ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ ì—†ìŒ: {gemini_path}")
    
    # 3. ê²°ê³¼ ë¹„êµ ë° ì¶œë ¥
    print(f"\nğŸ“Š ì˜¬ë°”ë¥¸ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¹„êµ")
    print("=" * 60)
    
    if results:
        comparison_data = []
        for model, data in results.items():
            if data["avg_search_time"] != float('inf'):
                comparison_data.append({
                    "ëª¨ë¸": data["model_name"],
                    "ë²¡í„°ì°¨ì›": "1024D" if model == "E5" else "3072D",
                    "í‰ê·  ê²€ìƒ‰ì‹œê°„(ms)": f"{data['avg_search_time']*1000:.1f}",
                    "í‰ê·  Precision@5": f"{data['avg_precision']:.3f}",
                    "ì²˜ë¦¬ëŸ‰(QPS)": f"{data['qps']:.1f}",
                    "ì¢…í•©ì ìˆ˜": f"{(data['avg_precision'] * 60 + min(data['qps']/10, 1) * 40):.1f}"
                })
            else:
                comparison_data.append({
                    "ëª¨ë¸": data["model_name"],
                    "ë²¡í„°ì°¨ì›": "1024D" if model == "E5" else "3072D",
                    "í‰ê·  ê²€ìƒ‰ì‹œê°„(ms)": "ì‹¤íŒ¨",
                    "í‰ê·  Precision@5": f"{data['avg_precision']:.3f}",
                    "ì²˜ë¦¬ëŸ‰(QPS)": "0",
                    "ì¢…í•©ì ìˆ˜": "0"
                })
        
        df = pd.DataFrame(comparison_data)
        print(df.to_string(index=False))
        
        # ìŠ¹ì íŒì • (ìœ íš¨í•œ ê²°ê³¼ë§Œ)
        valid_results = {k: v for k, v in results.items() if v["avg_search_time"] != float('inf')}
        
        if len(valid_results) == 2:
            e5_score = valid_results["E5"]["avg_precision"] * 0.6 + min(valid_results["E5"]["qps"]/1000, 1) * 0.4
            gemini_score = valid_results["Gemini"]["avg_precision"] * 0.6 + min(valid_results["Gemini"]["qps"]/1000, 1) * 0.4
            
            print(f"\nğŸ† ìµœì¢… ìŠ¹ì:")
            if e5_score > gemini_score:
                print(f"   ğŸ¥‡ E5-Large ìŠ¹ë¦¬! (ì ìˆ˜: {e5_score:.3f} vs {gemini_score:.3f})")
                print(f"   ğŸ’ª ë¹ ë¥¸ ì†ë„ì™€ ì•ˆì •ì„±ìœ¼ë¡œ ìŠ¹ë¦¬")
            elif gemini_score > e5_score:
                print(f"   ğŸ¥‡ Gemini ìŠ¹ë¦¬! (ì ìˆ˜: {gemini_score:.3f} vs {e5_score:.3f})")
                print(f"   ğŸ§  ê³ ì°¨ì› ì„ë² ë”©ìœ¼ë¡œ ìŠ¹ë¦¬")
            else:
                print(f"   ğŸ¤ ë¬´ìŠ¹ë¶€! (ì ìˆ˜: {e5_score:.3f})")
        elif len(valid_results) == 1:
            winner = list(valid_results.keys())[0]
            print(f"\nğŸ† {winner} ëª¨ë¸ë§Œ ì„±ê³µì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¨")
        else:
            print(f"\nâŒ ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # 4. ê²°ê³¼ ì €ì¥
    output_file = "proper_benchmark_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        # float('inf') ì²˜ë¦¬
        def clean_results(obj):
            if isinstance(obj, dict):
                return {k: clean_results(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [clean_results(v) for v in obj]
            elif obj == float('inf'):
                return None
            else:
                return obj
        
        json.dump(clean_results(results), f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    print(f"\nâœ… ì˜¬ë°”ë¥¸ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print(f"ğŸ’¡ ê° ëª¨ë¸ì´ ìì‹ ì˜ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
    return results

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.WARNING)
    
    try:
        results = run_proper_benchmark()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc() 