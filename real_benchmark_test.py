#!/usr/bin/env python3
"""
ì‹¤ì œ ì˜ë£Œ ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
E5, Gemini ë²¡í„° ìŠ¤í† ì–´ ì„±ëŠ¥ ë¹„êµ
"""

import json
import logging
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

# FAISS ë° Langchain ì„í¬íŠ¸
try:
    import faiss
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    print("âœ… í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("pip install faiss-cpu langchain langchain-community langchain-google-genai ì‹¤í–‰ í•„ìš”")
    sys.exit(1)

class RealVectorStoreBenchmark:
    """ì‹¤ì œ ë²¡í„° ìŠ¤í† ì–´ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    
    def __init__(self):
        self.results = {}
        
    def load_e5_vector_store(self, store_path: str):
        """E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
        try:
            print(f"ğŸ”„ E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©: {store_path}")
            
            # E5 ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embedding_model = HuggingFaceEmbeddings(
                model_name="intfloat/multilingual-e5-large",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            
            # FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            vector_store = FAISS.load_local(
                store_path,
                embedding_model,
                allow_dangerous_deserialization=True
            )
            
            print(f"âœ… E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
            print(f"   - ë²¡í„° ê°œìˆ˜: {vector_store.index.ntotal}")
            print(f"   - ë²¡í„° ì°¨ì›: {vector_store.index.d}")
            
            return vector_store, embedding_model
            
        except Exception as e:
            print(f"âŒ E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None
    
    def load_gemini_vector_store(self, store_path: str, api_key: str = None):
        """Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ"""
        try:
            print(f"ğŸ”„ Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë”©: {store_path}")
            
            if not api_key:
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°
                api_key = os.getenv('GOOGLE_API_KEY')
                if not api_key:
                    print("âš ï¸ GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return None, None
            
            # Gemini ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            embedding_model = GoogleGenerativeAIEmbeddings(
                model="models/gemini-embedding-exp-03-07",
                google_api_key=api_key
            )
            
            # FAISS ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            vector_store = FAISS.load_local(
                store_path,
                embedding_model,
                allow_dangerous_deserialization=True
            )
            
            print(f"âœ… Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
            print(f"   - ë²¡í„° ê°œìˆ˜: {vector_store.index.ntotal}")
            print(f"   - ë²¡í„° ì°¨ì›: {vector_store.index.d}")
            
            return vector_store, embedding_model
            
        except Exception as e:
            print(f"âŒ Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None

    def precision_at_k(self, relevant_docs: List[str], retrieved_docs: List[Dict], k: int) -> float:
        """Precision@K ê³„ì‚° (ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ìš©)"""
        if k == 0 or not retrieved_docs:
            return 0.0
        
        retrieved_k = retrieved_docs[:k]
        relevant_retrieved = 0
        
        for doc in retrieved_k:
            # ë¬¸ì„œ ë‚´ìš©ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°
            content = doc.page_content.lower()
            for relevant_concept in relevant_docs:
                if relevant_concept.lower() in content:
                    relevant_retrieved += 1
                    break
        
        return relevant_retrieved / k

    def perform_search_benchmark(self, vector_store, model_name: str, test_queries: List[Dict]):
        """ì‹¤ì œ ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nğŸ” {model_name} ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        search_times = []
        precision_scores = []
        search_results = []
        
        for i, query_data in enumerate(test_queries):
            query = query_data["query"]
            expected_concepts = query_data["relevant_concepts"]
            
            print(f"   {i+1}. ì¿¼ë¦¬: '{query}'")
            
            # ê²€ìƒ‰ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            try:
                # ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
                results = vector_store.similarity_search(query, k=5)
                search_time = time.time() - start_time
                search_times.append(search_time)
                
                # Precision@5 ê³„ì‚°
                precision = self.precision_at_k(expected_concepts, results, 5)
                precision_scores.append(precision)
                
                print(f"      ê²€ìƒ‰ ì‹œê°„: {search_time*1000:.1f}ms")
                print(f"      Precision@5: {precision:.3f}")
                
                # ìƒìœ„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                if results:
                    preview = results[0].page_content[:100].replace('\n', ' ')
                    print(f"      ìƒìœ„ ê²°ê³¼: {preview}...")
                
                search_results.append({
                    "query": query,
                    "search_time": search_time,
                    "precision": precision,
                    "num_results": len(results)
                })
                
            except Exception as e:
                print(f"      âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                search_times.append(float('inf'))
                precision_scores.append(0.0)
        
        # ì„±ëŠ¥ ìš”ì•½
        avg_search_time = np.mean([t for t in search_times if t != float('inf')])
        avg_precision = np.mean(precision_scores)
        
        print(f"\nğŸ“Š {model_name} ì„±ëŠ¥ ìš”ì•½:")
        print(f"   í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time*1000:.1f}ms")
        print(f"   í‰ê·  Precision@5: {avg_precision:.3f}")
        print(f"   ì´ˆë‹¹ ì²˜ë¦¬ëŸ‰: {1/avg_search_time:.1f} QPS")
        
        return {
            "model_name": model_name,
            "avg_search_time": avg_search_time,
            "avg_precision": avg_precision,
            "qps": 1/avg_search_time if avg_search_time > 0 else 0,
            "search_results": search_results
        }

def create_medical_test_queries():
    """ì˜ë£Œ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìƒì„±"""
    return [
        {
            "query": "ë‹¹ë‡¨ë³‘ í™˜ì í˜ˆë‹¹ ê´€ë¦¬",
            "relevant_concepts": ["ë‹¹ë‡¨ë³‘", "í˜ˆë‹¹", "ì¸ìŠë¦°", "í˜ˆë‹¹ì¡°ì ˆ"]
        },
        {
            "query": "ê³ í˜ˆì•• ì§„ë‹¨ ì¹˜ë£Œ",
            "relevant_concepts": ["ê³ í˜ˆì••", "í˜ˆì••", "í˜ˆì••ì¸¡ì •", "í˜ˆì••ì•½"]
        },
        {
            "query": "ì‹¬ì¥ë³‘ ì¦ìƒ",
            "relevant_concepts": ["ì‹¬ì¥", "ì‹¬ê·¼ê²½ìƒ‰", "í˜‘ì‹¬ì¦", "í‰í†µ"]
        },
        {
            "query": "íë ´ ì§„ë‹¨",
            "relevant_concepts": ["íë ´", "ê¸°ì¹¨", "ë°œì—´", "í˜¸í¡"]
        },
        {
            "query": "ë‡Œì¡¸ì¤‘ ì‘ê¸‰ì²˜ì¹˜",
            "relevant_concepts": ["ë‡Œì¡¸ì¤‘", "ë§ˆë¹„", "ì‘ê¸‰", "ë‡Œ"]
        },
        {
            "query": "ê°„ì—¼ ê²€ì‚¬",
            "relevant_concepts": ["ê°„ì—¼", "ê°„", "ê°„ê¸°ëŠ¥", "ê²€ì‚¬"]
        },
        {
            "query": "ì‹ ë¶€ì „ ì¹˜ë£Œ",
            "relevant_concepts": ["ì‹ ë¶€ì „", "ì‹ ì¥", "íˆ¬ì„", "í¬ë ˆì•„í‹°ë‹Œ"]
        },
        {
            "query": "ìš°ìš¸ì¦ ì•½ë¬¼ì¹˜ë£Œ",
            "relevant_concepts": ["ìš°ìš¸ì¦", "ì •ì‹ ", "í•­ìš°ìš¸ì œ", "ì•½ë¬¼"]
        }
    ]

def run_real_benchmark():
    """ì‹¤ì œ ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    
    print("ğŸš€ ì‹¤ì œ ì˜ë£Œ ë²¡í„° ìŠ¤í† ì–´ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("=" * 60)
    
    # ë²¤ì¹˜ë§ˆí¬ ê°ì²´ ìƒì„±
    benchmark = RealVectorStoreBenchmark()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„
    test_queries = create_medical_test_queries()
    print(f"ğŸ“‹ ì¤€ë¹„ëœ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
    
    # ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ ì„¤ì •
    base_path = "VectorStore2/vector_stores"
    e5_path = f"{base_path}/medical_vector_store_e5"
    gemini_path = f"{base_path}/medical_vector_store"
    
    results = {}
    
    # 1. E5 ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸
    if os.path.exists(e5_path):
        print(f"\nğŸ” E5 ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸")
        e5_store, e5_model = benchmark.load_e5_vector_store(e5_path)
        
        if e5_store:
            e5_results = benchmark.perform_search_benchmark(
                e5_store, "E5-Large", test_queries
            )
            results["E5"] = e5_results
        else:
            print("âŒ E5 ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨")
    else:
        print(f"âš ï¸ E5 ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ ì—†ìŒ: {e5_path}")
    
    # 2. Gemini ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸
    if os.path.exists(gemini_path):
        print(f"\nğŸ” Gemini ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸")
        gemini_store, gemini_model = benchmark.load_gemini_vector_store(gemini_path)
        
        if gemini_store:
            gemini_results = benchmark.perform_search_benchmark(
                gemini_store, "Gemini-exp-03-07", test_queries
            )
            results["Gemini"] = gemini_results
        else:
            print("âŒ Gemini ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨")
    else:
        print(f"âš ï¸ Gemini ë²¡í„° ìŠ¤í† ì–´ ê²½ë¡œ ì—†ìŒ: {gemini_path}")
    
    # 3. ê²°ê³¼ ë¹„êµ ë° ì¶œë ¥
    print(f"\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¹„êµ")
    print("=" * 60)
    
    if results:
        comparison_data = []
        for model, data in results.items():
            comparison_data.append({
                "ëª¨ë¸": data["model_name"],
                "í‰ê·  ê²€ìƒ‰ì‹œê°„(ms)": f"{data['avg_search_time']*1000:.1f}",
                "í‰ê·  Precision@5": f"{data['avg_precision']:.3f}",
                "ì²˜ë¦¬ëŸ‰(QPS)": f"{data['qps']:.1f}",
                "ì¢…í•©ì ìˆ˜": f"{(data['avg_precision'] * 50 + min(data['qps']/10, 1) * 50):.1f}"
            })
        
        df = pd.DataFrame(comparison_data)
        print(df.to_string(index=False))
        
        # ìŠ¹ì íŒì •
        if len(results) == 2:
            e5_score = results["E5"]["avg_precision"] * 0.6 + min(results["E5"]["qps"]/1000, 1) * 0.4
            gemini_score = results["Gemini"]["avg_precision"] * 0.6 + min(results["Gemini"]["qps"]/1000, 1) * 0.4
            
            print(f"\nğŸ† ìµœì¢… ìŠ¹ì:")
            if e5_score > gemini_score:
                print(f"   ğŸ¥‡ E5-Large ìŠ¹ë¦¬! (ì ìˆ˜: {e5_score:.3f} vs {gemini_score:.3f})")
            elif gemini_score > e5_score:
                print(f"   ğŸ¥‡ Gemini ìŠ¹ë¦¬! (ì ìˆ˜: {gemini_score:.3f} vs {e5_score:.3f})")
            else:
                print(f"   ğŸ¤ ë¬´ìŠ¹ë¶€! (ì ìˆ˜: {e5_score:.3f})")
    
    # 4. ê²°ê³¼ ì €ì¥
    output_file = "benchmark_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    print(f"\nâœ… ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    return results

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.WARNING)
    
    try:
        results = run_real_benchmark()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc() 