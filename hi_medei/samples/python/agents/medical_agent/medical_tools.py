"""Medical tools for patient search, document generation, and analysis."""

import json
import os
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
from langchain.tools import BaseTool
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from pydantic import BaseModel, Field

from models import (
    DepartmentType,
    DrugInteraction,
    MedicalAnalysis,
    MedicalRecord,
    Patient,
    PatientSearchQuery,
    PatientSearchResult,
    SOAPNote,
    UrgencyLevel,
)


class PatientSearchTool(BaseTool):
    """í™˜ì ê²€ìƒ‰ ë„êµ¬"""
    
    name: str = "patient_search"
    description: str = "í™˜ì ID, ì´ë¦„, ì¦ìƒìœ¼ë¡œ í™˜ìë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    data_path: str = Field(default="../../../../VectorStore2/medical_data")
    patients_data: Dict[str, List[Dict]] = Field(default_factory=dict)
    
    def __init__(self, data_path: str = "../../../../VectorStore2/medical_data", **kwargs):
        super().__init__(**kwargs)
        self.data_path = data_path
        self.patients_data = self._load_patient_data()
    
    def _load_patient_data(self) -> Dict[str, List[Dict]]:
        """í™˜ì ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        data = {}
        
        # VectorStore2/medical_dataì˜ JSON íŒŒì¼ ë§¤í•‘
        file_mappings = {
            "cardiology_patients.json": "ì‹¬ì¥ë‚´ê³¼",
            "emergency_patients.json": "ì‘ê¸‰ì˜í•™ê³¼", 
            "internal_medicine_patients.json": "ë‚´ê³¼",
            "neurology_patients.json": "ì‹ ê²½ê³¼",
            "surgery_patients.json": "ì™¸ê³¼"
        }
        
        print(f"Loading patient data from: {self.data_path}")
        
        for filename, department in file_mappings.items():
            file_path = os.path.join(self.data_path, filename)
            print(f"Checking file: {file_path}")
            
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        patient_list = json.load(f)
                        dept_data = []
                        
                        # JSON íŒŒì¼ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° í™˜ìì— department ì¶”ê°€
                        if isinstance(patient_list, list):
                            for patient in patient_list:
                                patient['department'] = department
                                dept_data.append(patient)
                        else:
                            # ë‹¨ì¼ í™˜ì ê°ì²´ì¸ ê²½ìš°
                            patient_list['department'] = department
                            dept_data.append(patient_list)
                        
                        data[department] = dept_data
                        print(f"âœ… Loaded {filename}: {len(dept_data)} patients")
                        
                except Exception as e:
                    print(f"âŒ Error loading {filename}: {e}")
            else:
                print(f"âŒ File not found: {file_path}")
        
        print(f"\nğŸ“Š ì´ ë¡œë“œëœ ë°ì´í„°: {len(data)} ë¶€ì„œ")
        total_patients = 0
        for dept, patients in data.items():
            patient_count = len(patients)
            total_patients += patient_count
            print(f"  ğŸ¥ {dept}: {patient_count}ëª…")
        print(f"  ğŸ‘¥ ì „ì²´ í™˜ì ìˆ˜: {total_patients}ëª…\n")
        
        return data
    
    def _run(self, query: str, query_type: str = "name", max_results: int = 10) -> str:
        """í™˜ì ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        start_time = time.time()
        results = []
        
        query_lower = query.lower()
        
        # ì¿¼ë¦¬ì—ì„œ ê²€ìƒ‰ íƒ€ì…ê³¼ ê°’ì„ íŒŒì‹±
        if ":" in query:
            parts = query.split(":", 1)
            if len(parts) == 2:
                search_type = parts[0].strip()
                search_value = parts[1].strip()
                
                if "ì´ë¦„" in search_type or "name" in search_type.lower():
                    query_type = "name"
                    query_lower = search_value.lower()
                elif "ì¦ìƒ" in search_type or "symptom" in search_type.lower():
                    query_type = "symptom"
                    query_lower = search_value.lower()
                elif "ì§„ë‹¨" in search_type or "diagnosis" in search_type.lower():
                    query_type = "diagnosis"
                    query_lower = search_value.lower()
        
        for dept, patients in self.patients_data.items():
            for patient in patients:
                match_found = False
                
                if query_type == "name" and query_lower in patient.get('name', '').lower():
                    match_found = True
                elif query_type == "id" and query_lower in patient.get('id', '').lower():
                    match_found = True
                elif query_type == "diagnosis" and query_lower in patient.get('diagnosis', '').lower():
                    match_found = True
                elif query_type == "symptom":
                    symptoms = patient.get('symptoms', [])
                    if isinstance(symptoms, list):
                        if any(query_lower in symptom.lower() for symptom in symptoms):
                            match_found = True
                    elif isinstance(symptoms, str) and query_lower in symptoms.lower():
                        match_found = True
                
                if match_found:
                    results.append(patient)
        
        search_time = time.time() - start_time
        
        # ê²°ê³¼ ì œí•œ
        results = results[:max_results]
        
        return json.dumps({
            "patients": results,
            "total_count": len(results),
            "search_time": search_time,
            "query": query,
            "query_type": query_type
        }, ensure_ascii=False, indent=2)


class VectorSearchTool(BaseTool):
    """ë²¡í„° ê²€ìƒ‰ ë„êµ¬ - ìœ ì‚¬ ì¦ìƒ í™˜ì ê²€ìƒ‰"""
    
    name: str = "vector_search"
    description: str = "ì¦ìƒì„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ í™˜ìë¥¼ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."
    openai_api_key: str = Field(default="")
    vectorstore: Optional[str] = Field(default=None)
    
    def __init__(self, openai_api_key: str, **kwargs):
        super().__init__(**kwargs)
        self.openai_api_key = openai_api_key
        self.vectorstore = None
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            # GeminiVectorStore ê²½ë¡œ ì‚¬ìš©
            gemini_vector_path = "/Users/sindong-u/coding/project/hi_medei/GeminiVectorStore/medical_vector_store"
            
            # FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„
            import pickle

            import faiss

            # ì¸ë±ìŠ¤ íŒŒì¼ë“¤ í™•ì¸
            index_path = os.path.join(gemini_vector_path, "index.faiss")
            pkl_path = os.path.join(gemini_vector_path, "index.pkl")
            
            if os.path.exists(index_path) and os.path.exists(pkl_path):
                print(f"GeminiVectorStore ë¡œë“œ ì‹œë„: {gemini_vector_path}")
                # ê°„ë‹¨í•œ FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
                self.vectorstore = "faiss_loaded"  # ì‹¤ì œ êµ¬í˜„ì€ FAISS ë¡œë“œ
                print("GeminiVectorStore ë¡œë“œ ì„±ê³µ")
            else:
                print("GeminiVectorStore íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"Vector store initialization error: {e}")
    
    def _run(self, symptoms: str, k: int = 5) -> str:
        """ìœ ì‚¬ ì¦ìƒ í™˜ìë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        if not self.vectorstore:
            return json.dumps({"error": "Vector store not available"})
        
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” FAISS ê²€ìƒ‰ì„ ìˆ˜í–‰
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ ê²°ê³¼ ë°˜í™˜
            results = [
                {
                    "content": f"ìœ ì‚¬ ì¦ìƒ í™˜ì ì‚¬ë¡€: {symptoms}ì™€ ê´€ë ¨ëœ í™˜ì",
                    "metadata": {"patient_id": "SIM001", "similarity": 0.85},
                    "similarity_score": 0.85
                },
                {
                    "content": f"{symptoms} ì¦ìƒì„ ë³´ì¸ ê³¼ê±° í™˜ì ê¸°ë¡",
                    "metadata": {"patient_id": "SIM002", "similarity": 0.78},
                    "similarity_score": 0.78
                }
            ]
            
            return json.dumps({
                "similar_cases": results,
                "query": symptoms,
                "total_found": len(results),
                "source": "GeminiVectorStore"
            }, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({"error": f"Vector search failed: {e}"})


class SOAPNoteGeneratorTool(BaseTool):
    """SOAP ë…¸íŠ¸ ìƒì„± ë„êµ¬"""
    
    name: str = "soap_note_generator"
    description: str = "í™˜ì ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ SOAP ë…¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    
    def _run(self, patient_data: str) -> str:
        """SOAP ë…¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            data = json.loads(patient_data)
            
            # SOAP ë…¸íŠ¸ êµ¬ì¡° ìƒì„±
            subjective = self._generate_subjective(data)
            objective = self._generate_objective(data)
            assessment = self._generate_assessment(data)
            plan = self._generate_plan(data)
            
            soap_note = {
                "record_id": data.get('record_id', f"SOAP_{datetime.now().strftime('%Y%m%d_%H%M%S')}"),
                "subjective": subjective,
                "objective": objective,
                "assessment": assessment,
                "plan": plan,
                "created_by": "AI Medical Agent",
                "created_at": datetime.now().isoformat()
            }
            
            return json.dumps(soap_note, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({"error": f"SOAP note generation failed: {e}"})
    
    def _generate_subjective(self, data: Dict) -> str:
        """ì£¼ê´€ì  ì •ë³´ (S) ìƒì„±"""
        subjective_parts = []
        
        if 'chief_complaint' in data:
            subjective_parts.append(f"ì£¼ í˜¸ì†Œ: {data['chief_complaint']}")
        
        if 'symptoms' in data:
            symptoms_text = ", ".join(data['symptoms'])
            subjective_parts.append(f"ì¦ìƒ: {symptoms_text}")
        
        if 'pain_scale' in data:
            subjective_parts.append(f"í†µì¦ ì •ë„: {data['pain_scale']}/10")
        
        return "\n".join(subjective_parts)
    
    def _generate_objective(self, data: Dict) -> str:
        """ê°ê´€ì  ì •ë³´ (O) ìƒì„±"""
        objective_parts = []
        
        if 'vital_signs' in data:
            vital_signs = data['vital_signs']
            vital_text = []
            for key, value in vital_signs.items():
                vital_text.append(f"{key}: {value}")
            objective_parts.append(f"í™œë ¥ì§•í›„: {', '.join(vital_text)}")
        
        if 'physical_exam' in data:
            objective_parts.append(f"ì‹ ì²´ê²€ì‚¬: {data['physical_exam']}")
        
        if 'lab_results' in data:
            objective_parts.append(f"ê²€ì‚¬ê²°ê³¼: {data['lab_results']}")
        
        return "\n".join(objective_parts)
    
    def _generate_assessment(self, data: Dict) -> str:
        """í‰ê°€ (A) ìƒì„±"""
        assessment_parts = []
        
        if 'diagnosis' in data:
            if isinstance(data['diagnosis'], list):
                for i, diag in enumerate(data['diagnosis'], 1):
                    assessment_parts.append(f"{i}. {diag}")
            else:
                assessment_parts.append(f"1. {data['diagnosis']}")
        
        if 'differential_diagnosis' in data:
            assessment_parts.append(f"ê°ë³„ì§„ë‹¨: {data['differential_diagnosis']}")
        
        return "\n".join(assessment_parts)
    
    def _generate_plan(self, data: Dict) -> str:
        """ê³„íš (P) ìƒì„±"""
        plan_parts = []
        
        if 'medications' in data:
            plan_parts.append("ì²˜ë°©:")
            for med in data['medications']:
                if isinstance(med, dict):
                    med_text = f"- {med.get('name', '')} {med.get('dosage', '')} {med.get('frequency', '')}"
                else:
                    med_text = f"- {med}"
                plan_parts.append(med_text)
        
        if 'follow_up' in data:
            plan_parts.append(f"ì¶”í›„ ê´€ë¦¬: {data['follow_up']}")
        
        if 'patient_education' in data:
            plan_parts.append(f"í™˜ì êµìœ¡: {data['patient_education']}")
        
        return "\n".join(plan_parts)


class DrugInteractionCheckerTool(BaseTool):
    """ì•½ë¬¼ ìƒí˜¸ì‘ìš© ê²€ì‚¬ ë„êµ¬"""
    
    name: str = "drug_interaction_checker"
    description: str = "ì²˜ë°©ëœ ì•½ë¬¼ë“¤ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."
    interaction_db: Dict = Field(default_factory=dict)
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # ê°„ë‹¨í•œ ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë°ì´í„°ë² ì´ìŠ¤ (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ API ì‚¬ìš©)
        self.interaction_db = {
            ("ì•„ìŠ¤í”¼ë¦°", "ì™€íŒŒë¦°"): {
                "severity": "ë†’ìŒ",
                "description": "ì¶œí˜ˆ ìœ„í—˜ ì¦ê°€",
                "recommendation": "INR ëª¨ë‹ˆí„°ë§ ê°•í™”"
            },
            ("ë©”íŠ¸í¬ë¥´ë¯¼", "ìš”ì˜¤ë“œ ì¡°ì˜ì œ"): {
                "severity": "ë³´í†µ",
                "description": "ì –ì‚°ì¦ ìœ„í—˜",
                "recommendation": "ì¡°ì˜ì œ ì‚¬ìš© ì „í›„ ë©”íŠ¸í¬ë¥´ë¯¼ ì¤‘ë‹¨"
            }
        }
    
    def _run(self, medications: str) -> str:
        """ì•½ë¬¼ ìƒí˜¸ì‘ìš©ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
        try:
            med_list = json.loads(medications)
            interactions = []
            
            for i in range(len(med_list)):
                for j in range(i + 1, len(med_list)):
                    drug1 = med_list[i].get('name', '') if isinstance(med_list[i], dict) else med_list[i]
                    drug2 = med_list[j].get('name', '') if isinstance(med_list[j], dict) else med_list[j]
                    
                    # ìƒí˜¸ì‘ìš© ê²€ì‚¬
                    interaction_key = (drug1, drug2)
                    reverse_key = (drug2, drug1)
                    
                    if interaction_key in self.interaction_db:
                        interaction_data = self.interaction_db[interaction_key]
                        interactions.append({
                            "drug1": drug1,
                            "drug2": drug2,
                            **interaction_data
                        })
                    elif reverse_key in self.interaction_db:
                        interaction_data = self.interaction_db[reverse_key]
                        interactions.append({
                            "drug1": drug2,
                            "drug2": drug1,
                            **interaction_data
                        })
            
            return json.dumps({
                "interactions": interactions,
                "total_interactions": len(interactions),
                "checked_medications": med_list
            }, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({"error": f"Drug interaction check failed: {e}"})


class UrgencyAssessmentTool(BaseTool):
    """ì‘ê¸‰ë„ í‰ê°€ ë„êµ¬"""
    
    name: str = "urgency_assessment"
    description: str = "í™˜ìì˜ ì¦ìƒê³¼ í™œë ¥ì§•í›„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ê¸‰ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."
    
    def _run(self, patient_data: str) -> str:
        """ì‘ê¸‰ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
        try:
            data = json.loads(patient_data)
            urgency_score = 0
            factors = []
            
            # í™œë ¥ì§•í›„ í‰ê°€
            vital_signs = data.get('vital_signs', {})
            
            # í˜ˆì•• í‰ê°€
            if 'systolic_bp' in vital_signs:
                systolic = vital_signs['systolic_bp']
                if systolic > 180 or systolic < 90:
                    urgency_score += 3
                    factors.append("í˜ˆì•• ì´ìƒ")
            
            # ë§¥ë°• í‰ê°€
            if 'heart_rate' in vital_signs:
                hr = vital_signs['heart_rate']
                if hr > 120 or hr < 50:
                    urgency_score += 2
                    factors.append("ë§¥ë°• ì´ìƒ")
            
            # ì²´ì˜¨ í‰ê°€
            if 'temperature' in vital_signs:
                temp = vital_signs['temperature']
                if temp > 39.0 or temp < 35.0:
                    urgency_score += 2
                    factors.append("ì²´ì˜¨ ì´ìƒ")
            
            # ì¦ìƒ í‰ê°€
            symptoms = data.get('symptoms', [])
            critical_symptoms = ['í‰í†µ', 'í˜¸í¡ê³¤ë€', 'ì˜ì‹ì €í•˜', 'ì‹¬í•œë³µí†µ', 'ì¶œí˜ˆ']
            
            for symptom in symptoms:
                if any(critical in symptom for critical in critical_symptoms):
                    urgency_score += 3
                    factors.append(f"ìœ„í—˜ ì¦ìƒ: {symptom}")
            
            # ì‘ê¸‰ë„ ê²°ì •
            if urgency_score >= 7:
                urgency_level = UrgencyLevel.CRITICAL
            elif urgency_score >= 5:
                urgency_level = UrgencyLevel.HIGH
            elif urgency_score >= 3:
                urgency_level = UrgencyLevel.MEDIUM
            else:
                urgency_level = UrgencyLevel.LOW
            
            return json.dumps({
                "urgency_level": urgency_level.value,
                "urgency_score": urgency_score,
                "contributing_factors": factors,
                "recommendations": self._get_urgency_recommendations(urgency_level)
            }, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({"error": f"Urgency assessment failed: {e}"})
    
    def _get_urgency_recommendations(self, urgency_level: UrgencyLevel) -> List[str]:
        """ì‘ê¸‰ë„ë³„ ê¶Œì¥ì‚¬í•­ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        recommendations = {
            UrgencyLevel.CRITICAL: [
                "ì¦‰ì‹œ ì‘ê¸‰ì‹¤ ì´ì†¡",
                "í™œë ¥ì§•í›„ ì§€ì† ëª¨ë‹ˆí„°ë§",
                "ì‘ê¸‰ì²˜ì¹˜ ì¤€ë¹„"
            ],
            UrgencyLevel.HIGH: [
                "ìš°ì„  ì§„ë£Œ í•„ìš”",
                "30ë¶„ ì´ë‚´ ì¬í‰ê°€",
                "ì „ë¬¸ì˜ ìƒë‹´"
            ],
            UrgencyLevel.MEDIUM: [
                "1ì‹œê°„ ì´ë‚´ ì§„ë£Œ",
                "ì¦ìƒ ë³€í™” ê´€ì°°",
                "í•„ìš”ì‹œ ì¬í‰ê°€"
            ],
            UrgencyLevel.LOW: [
                "ì¼ë°˜ ì§„ë£Œ ëŒ€ê¸°",
                "ì¦ìƒ ì•…í™”ì‹œ ì¬í‰ê°€",
                "í™˜ì êµìœ¡ ì œê³µ"
            ]
        }
        
        return recommendations.get(urgency_level, [])


class HybridSearchTool(BaseTool):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë„êµ¬ - JSON ë°ì´í„°ì™€ ë²¡í„° ê²€ìƒ‰ ê²°í•©"""
    
    name: str = "hybrid_search"
    description: str = "JSON ë°ì´í„°ì™€ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ í¬ê´„ì ì¸ í™˜ì ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
    data_path: str = Field(default="")
    openai_api_key: str = Field(default="")
    patient_search: Optional[PatientSearchTool] = Field(default=None)
    vector_search: Optional[VectorSearchTool] = Field(default=None)
    
    def __init__(self, data_path: str, openai_api_key: str, **kwargs):
        super().__init__(**kwargs)
        self.data_path = data_path
        self.openai_api_key = openai_api_key
        self.patient_search = PatientSearchTool(data_path=data_path)
        self.vector_search = VectorSearchTool(openai_api_key=openai_api_key)
    
    def _run(self, query: str, search_type: str = "comprehensive") -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            results = {
                "query": query,
                "search_type": search_type,
                "json_results": {},
                "vector_results": {},
                "combined_insights": []
            }
            
            # 1. JSON ë°ì´í„° ê²€ìƒ‰
            # ì¿¼ë¦¬ í˜•íƒœì— ë”°ë¼ ì ì ˆí•œ ê²€ìƒ‰ ìˆ˜í–‰
            if ":" not in query:
                # ë‹¨ìˆœ í‚¤ì›Œë“œì¸ ê²½ìš° ì§„ë‹¨ëª…ìœ¼ë¡œ ê²€ìƒ‰
                search_query = f"ì§„ë‹¨: {query}"
            else:
                search_query = query
            
            json_result = self.patient_search._run(search_query)
            results["json_results"] = json.loads(json_result)
            
            # 2. ë²¡í„° ê²€ìƒ‰ (ì¦ìƒ ê¸°ë°˜)
            vector_result = self.vector_search._run(query)
            results["vector_results"] = json.loads(vector_result)
            
            # 3. ê²°ê³¼ ê²°í•© ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights = []
            
            if results["json_results"]["total_count"] > 0:
                insights.append(f"êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ {results['json_results']['total_count']}ëª…ì˜ í™˜ìë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            if results["vector_results"].get("total_found", 0) > 0:
                insights.append(f"ìœ ì‚¬ ì¦ìƒ ê²€ìƒ‰ì—ì„œ {results['vector_results']['total_found']}ê°œì˜ ê´€ë ¨ ì‚¬ë¡€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            if not insights:
                insights.append("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            
            results["combined_insights"] = insights
            
            return json.dumps(results, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({"error": f"Hybrid search failed: {e}"})


class MCPConnectorTool(BaseTool):
    """MCP(Model Context Protocol) ì—°ê²° ë„êµ¬"""
    
    name: str = "mcp_connector"
    description: str = "ì™¸ë¶€ ì˜ë£Œ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì‹œìŠ¤í…œê³¼ MCPë¥¼ í†µí•´ ì—°ê²°í•©ë‹ˆë‹¤."
    mcp_endpoints: Dict[str, str] = Field(default_factory=dict)
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.mcp_endpoints = {
            "hospital_db": "http://localhost:8080/mcp/hospital",
            "medical_records": "http://localhost:8081/mcp/records",
            "drug_database": "http://localhost:8082/mcp/drugs"
        }
    
    def _run(self, query: str, endpoint: str = "hospital_db") -> str:
        """MCPë¥¼ í†µí•´ ì™¸ë¶€ ì‹œìŠ¤í…œì— ì¿¼ë¦¬ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤."""
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” HTTP ìš”ì²­ì„ ë³´ëƒ„
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ ë°˜í™˜
            
            if endpoint not in self.mcp_endpoints:
                return json.dumps({"error": f"Unknown endpoint: {endpoint}"})
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ MCP ì‘ë‹µ
            mcp_response = {
                "endpoint": endpoint,
                "query": query,
                "status": "success",
                "data": {
                    "message": f"MCP ì—°ê²°ì„ í†µí•´ {endpoint}ì—ì„œ '{query}' ê²€ìƒ‰ ì™„ë£Œ",
                    "external_results": [
                        {
                            "source": endpoint,
                            "content": f"{query}ì™€ ê´€ë ¨ëœ ì™¸ë¶€ ë°ì´í„°",
                            "confidence": 0.9
                        }
                    ]
                },
                "timestamp": datetime.now().isoformat()
            }
            
            return json.dumps(mcp_response, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return json.dumps({"error": f"MCP connection failed: {e}"}) 